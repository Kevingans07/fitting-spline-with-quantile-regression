---
title: "Group Project"
author: |
  By Nicholas Xu, Kevin Sutikno and Xuanlin Zhu
output:
  pdf_document:
    number_sections: yes
    fig_height: 4
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require("knitr")
```

```{r echo=FALSE}
set.seed(12345)
```


```{r}
n <- 1e3
x <- seq(0, 2*pi, length.out = n)
y <- sin(x) + rnorm(n, 0, 0.5)
dat <- data.frame(x = x, y = y)
plot(x, y)
```

```{r}
library(mgcv)
sm <- smoothCon(s(x, k = 10, bs = "cr"), data=dat, knots=NULL)[[1]]
X <- sm$X
S <- sm$S[[1]] # penalty matrix S

fit <- lm(y ~ X-1, data = dat)

matplot(X, x = x, type = 'l', ylab = "Spline basis function")
```

```{r}
# Computes ELF density and its derivatives w.r.t mu
dlf <- function(x, tau, mu, psi, log = FALSE, deriv = 0)
{
  sig <- 1
  y <- (x - mu) / sig
  out <- (1-tau) * y - psi * log(1 + exp(y / psi)) - log(sig * psi * beta(psi * (1 - tau), tau * psi))
  if (!log) out <- exp(out)
  if(deriv > 0)
  {
    out <- list("d" = out)
    dl <- dlogis(x, mu, psi*sig)
    pl <- plogis(x, mu, psi*sig)
    out$D <- sum((pl - (1-tau)) / sig)
    if(deriv > 1)
    {
      out$D2 <- sum(-dl / sig)
    }
  }
  return(out)
}

# Computes negative log-likelihood as a function of beta
negllkFun <- function(par, tau, psi, dat, X)
{
  mu <- X %*% par
  out <- - sum( dlf(x = dat, tau = tau, mu = mu, psi = psi, log = TRUE))
  return(out)
}

# Computes derivative of the log-likelihood w.r.t. beta
negGrad <- function(par, tau, psi, dat, X)
{
  mu <- X %*% par
  tmp <- lapply(1:length(mu),
                function(ii){
                  a <- - dlf(x = dat[ii], tau = tau, mu = mu[ii],
                  psi = psi, log = TRUE, deriv = 1)$D
                  return(a[1] * X[ii, ])
                }
  )
  out <- Reduce("+", tmp)
  return(out)
}
```

```{r}
# version one of penalty -> this is smoothed
pen_negllk <- function(par, tau, psi, dat, X, S, lambda) {
  negllkFun(par, tau, psi, dat, X) + as.numeric(lambda * t(par) %*% (S %*% par))
}

pen_negGrad <- function(par, tau, psi, dat, X, S, lambda) {
  as.numeric(negGrad(par, tau, psi, dat, X)) + 2 * lambda * as.vector(S %*% par)
}

# second version of penalty
pen_ssqr2 <- function(beta, X, y, S, 
                     lambda,tau, psi =0.1, sigma =1){
  mu <- X %*% beta
  res <- (y-mu)
  pen <- as.numeric(t(beta) %*% S %*% beta) #produces a 1x1 matrix
  penalty <- lambda * pen
  #loss <- sum((tau -(res<0))* res) 
  loss <- negllkFun(beta, tau, psi, y, X)
  
  as.numeric(loss+penalty)
}

pen_ssqr2_grad <- function(beta, X, y, S, 
                     lambda,tau, psi =0.1, sigma =1){
  
  grad_loss <- negGrad(beta, tau, psi, y, X)   # SAME GRADIENT
  grad_pen  <- 2 * lambda * S %*% beta
  grad_loss + grad_pen
  
}
```

```{r}
tau <- 0.9 #90th quantile
psi <- 0.1
lambda_1 <- 100
sigma <- 1

#true function
z_norm_90 <- qnorm(0.9)
sigma_true <-0.5 # true mean
sin_quantile_90 <- sin(x) +sigma_true * z_norm_90


fit_pen_1 <- optim(par = coef(fit),
                fn = pen_negllk,
                gr = pen_negGrad,
                tau = tau, psi = psi, dat = dat$y, X = X, S = S, lambda = lambda_1,
                method = "BFGS")

fit_pen_2 <- optim(par = coef(fit),
                 fn = pen_ssqr2,
                 gr = pen_ssqr2_grad,
                 tau = tau, psi = psi, y = dat$y, X = X, S = S, lambda = lambda_1,
                 method = "BFGS",
                 )

plot(x, y, col = "grey", main = paste("Quantile Regression tau =", tau))

lines(x, X %*% fit_pen_1$par, col = "red", lwd = 2)
lines(x, X %*% fit_pen_2$par, col = "yellow", lwd = 2) #this overlaps with other line as it has same value
lines(x, sin_quantile_90, col = "blue", lty = 2, lwd = 5) # True 90th quantile

legend("topright", legend = c("Data", "Fitted 1","Fitted 2", "True 90th quantile"), 
       col = c("grey", "red","yellow", "blue"), lty = c(NA, 1, 2), pch = c(1, NA, NA))
```

##Doing K-Fold Cross Validation to find optimal lambda that captures the model smoothly
```{r}
# -> we want to find lambda that represents the data (not too small lambda that will overfit the data(model) nor too large that oversmooth the model )

### --- PARAMETERS ---
k_folds <- 5
tau <- 0.9
psi <- 0.05
sigma <- 1
lambda_grid <- 10^seq(-3, 4, length.out = 25)  # 10^-3 to 10^4
set.seed(42)


n <- nrow(dat)
fold_ids <- sample(rep(1:k_folds, length.out = n))

# store mean validation loss
cv_results <- data.frame(lambda = lambda_grid,
                         sum_vall_loss = NA_real_)

# Precompute starting coefficients from full-data OLS (warm start)
start_coef <- coef(fit) #from lm(y ~ X - 1)

### --- K-FOLD LOOP over lambda values in grid ---
for (i in seq_along(lambda_grid)) {
  
  lambda <- lambda_grid[i]
  #fold_mean <- numeric(k_folds)
  fold_sum <- numeric(k_folds)

  for (fold in 1:k_folds) {

    # split
    train_idx <- which(fold_ids != fold)
    val_idx   <- which(fold_ids == fold)

    X_train <- X[train_idx, , drop = FALSE]
    y_train <- dat$y[train_idx]

    X_val   <- X[val_idx, , drop = FALSE]
    y_val   <- dat$y[val_idx]
    
    #OLS on training fold
    ols_train <- lm(y_train ~ X_train -1)
    start_beta <- coef(ols_train)
    if (length(start_beta) != ncol(X)) start_beta <- rep(0, ncol(X))
    
  

    # FIT on training (always same warm start for stability)
    fit_fold <- optim(par = start_beta,
                      fn = pen_ssqr2,
                      gr = pen_ssqr2_grad,
                      X = X_train,
                      y = y_train,
                      tau = tau, psi = psi,
                      S = S, lambda = lambda,
                      method = "BFGS")

    beta_hat <- fit_fold$par

    # VALIDATION PINBALL LOSS (NO PENALTY)
    resid_val <- as.numeric(y_val - X_val %*% beta_hat)
    pinball <- (tau - (resid_val < 0)) * resid_val

    #fold_mean[fold] <- mean(pinball)
    fold_sum[fold] <- sum(pinball) ## THIS WILL CALCULATE SUM CV LOSS, NOT MEAN CV LOSS
  }

  #cv_results$mean_val_loss[i] <- mean(fold_mean)
  cv_results$sum_val_loss[i] <- sum(fold_sum)
}

### --- CHOOSE BEST LAMBDA from sum cv loss---

#best_lambda_mean <- cv_results$lambda[which.min(cv_results$mean_val_loss)]
best_lambda_sum <- cv_results[which.min(cv_results$sum_val_loss), ]
best_lambda <- best_lambda_sum$lambda

#print(paste("Best λ (mean CV loss):", best_lambda_mean))
print(paste("Best λ (sum CV loss):",  best_lambda))
#paste("CV loss at optimal lambda is", round(best_lambda_sum, 6)) 
#optimal lambda when sum is minimal

  
# Refit final model on FULL DATA with best lambda
# Warm start: OLS on full data
ols_full <- lm(dat$y ~ X - 1)
start_full <- coef(ols_full)
if (length(start_full) != ncol(X)) start_full <- rep(0, ncol(X))

### --- PLOT CV CURVE ---
plot(log10(cv_results$lambda), cv_results$sum_val_loss,
     type = "b", pch = 19, col = "darkblue",
     xlab = "log10(lambda)",
     ylab = "SUM CV Loss",
     main = paste("CV for tau =", tau))

abline(v = log10(best_lambda),  col="purple", lty=2)


### --- FIT FINAL MODEL USING BEST LAMBDA ---
fit_best <- optim(par = start_full,
                   fn = pen_ssqr2,
                   gr = pen_ssqr2_grad,
                   X = X, y = dat$y,
                   tau = tau, psi = psi,
                   S = S, lambda = best_lambda,
                   method = "BFGS")

plot(dat$x, dat$y, col = "grey", main = paste("Quantile GAM (tau =", tau,")"))


### ALSO FIT λ=100 FOR COMPARISON
fit_100 <- optim(par = start_full,
                 fn = pen_ssqr2,
                 gr = pen_ssqr2_grad,
                 X = X, y = dat$y,
                 tau = tau, psi = psi,
                 S = S, lambda = 100,
                 method = "BFGS")

### --- PLOT RESULTS ---

lines(dat$x, X %*% fit_best$par, col = "red", lwd = 3)
lines(dat$x, X %*% fit_100$par, col = "purple", lwd = 3)
lines(x, sin_quantile_90, col = "blue", lty = 2, lwd = 3) #true function

legend("topright", 
       legend = c( paste("Optimal λ =", signif(best_lambda, 3)),
                   "λ = 100",
                   "True (90th quantile)" ), 
       col = c("red", "purple", "blue"),
       lty = c(1, 1, 2), lwd = 3
       )


```
```{r}

### --- FIT FINAL MODEL USING BEST LAMBDA ---
fit_best <- optim(par = start_full,
                   fn = pen_ssqr2,
                   gr = pen_ssqr2_grad,
                   X = X, y = dat$y,
                   tau = 0.5, psi = psi,
                   S = S, lambda = best_lambda,
                   method = "BFGS")

plot(dat$x, dat$y, col = "grey", main = paste("Quantile GAM (tau =", tau,")"))


### ALSO FIT λ=100 FOR COMPARISON
fit_100 <- optim(par = start_full,
                 fn = pen_ssqr2,
                 gr = pen_ssqr2_grad,
                 X = X, y = dat$y,
                 tau = tau, psi = psi,
                 S = S, lambda = 100,
                 method = "BFGS")

### --- PLOT RESULTS ---

lines(dat$x, X %*% fit_best$par, col = "red", lwd = 3)
lines(dat$x, X %*% fit_100$par, col = "purple", lwd = 3)
lines(x, sin_quantile_90, col = "blue", lty = 2, lwd = 3) #true function

legend("topright", 
       legend = c( paste("Optimal λ =", signif(best_lambda, 3)),
                   "λ = 100",
                   "True (90th quantile)" ), 
       col = c("red", "purple", "blue"),
       lty = c(1, 1, 2), lwd = 3
       )

```




